\chapter{Characterization of Data Rates}
\label{ch:annex-rate}

\section{Overview}

The data rates estimations take as input a number of parameters from
designs, requirements and studies.
Derived parameters are generated based on these inputs and code
captured in the \textit{dune-params} package\footnote{\url{https://github.com/DUNE/dune-params}}.
As the inputs and estimations are refined the results presented in
this annex are regenerated.

Because the triggering and readout strategy of the DAQ and analyses
are not yet fully understand, the data rate estimation makes some
broad assumptions and leaves open some choices described in the
following subsections.



\section{Thresholds}

There are three threshold considered for the purpose of the data rate estimates.
The thresholds are assumed to be applied on per-wire and on the basis
of their ADC value.
The thresholds are assumed to affect the data rate coming out of the
DAQ and do not intend to imply other thresholds used internally to the
DAQ (for example in the anticipated ``trigger stream'').
The thresholds are:

\begin{description}
\item[full-stream] The full-stream (FS) threshold is no threshold at all.
FS data is data where every time bin on every channel is read out.
\item[zero-suppressed] The zero-suppressed (ZS) threshold is applied
  at $\approx 3\sigma$ above the mean electronics noise level.
  Given the requirement on signal/noise ratio and the wire spacing,
  this effectively places an energy threshold of
  \chargezsthreshold.
\item[high-energy] The high-energy (HE) threshold is one that is
  placed high enough to remove activity from radioactive decays but
  low enough to not impact activity from beam neutrino interactions or
  proton decay.
  Study is needed to determine this threshold but it is taken to be
  \chargehethreshold.
\end{description}

The design of the DAQ is expected to allow FS data acquisition.
It is also expected to be flexible enough to allow for different
thresholds to be applied based on indications from the data itself.

\section{Sources of Data}

Data is expected to be produced from a number of sources.
Each source will produce a different rate and depending on the
threshold applied.
Their data rates are estimated individually for each source and threshold.
This provides a means to evaluate different assumptions, designs and
strategies.

The sources of data that are considered are:

\begin{description}
\item[in-spill] Activity in the detector which
  is coincident in time and space with the passage of neutrinos from
  the beam through the detector.
\item[cosmic-$\mu$] Activity due to the
  passing of cosmic-ray muons through the detector.
\item[radioactivity] Activity due to the decay of $^{39}$Ar,
  U/Th and other radioactive isotopes.
\item[atm-$\nu$] Activity which is not in-spill and which is
  consistent with interactions from atmospheric neutrinos.
\end{description}

\section{Fundamental Parameters}

This section provides the fundamental parameters taken as input to the
data rate estimations.
The parameters are summarized in
table~\ref{tab:fundamental-parameters}

\begin{table}[htbp]
  \centering
  \caption{The fundamental parameters serving as input to data rate estimations.}
  \input{annex-rate/gen/fundamental-parameters-table}
  \label{tab:fundamental-parameters}
\end{table}

\fixme{These aren't all.}

\section{Full-stream Data}

Full-stream (FS) data is acquired with no ADC threshold.
Estimating it's rate is an exact calculation and does not depend on
the activity in the detector or the noise level of the electronics.
It is obviously the most voluminous.
The parameters which apply to this data are given in table~\ref{tab:full-stream-parameters}.

\begin{table}[htbp]
  \centering
  \caption{Parameters pertaining to full-stream data rates.}
  \input{annex-rate/gen/full-stream-parameters-table}
  \label{tab:full-stream-parameters}
\end{table}

The expected data rates for two scenarios of FS data are given
in table~\ref{tab:full-stream-volume}.
The first block gives the data size of one DAQ readout
(\daqreadouttime).
The second is appropriate for any strategy that intends to record FS
data for each beam spill.
The third gives data volume relevant to an strategy to record FS data
for Supernova Burst candidates.
The final block shows what the DAQ is capable of producing on an annual basis.


\begin{table}[htbp]
  \centering
  \caption{Data volumes and rates for full-stream data
    acquisition.}
  \input{annex-rate/gen/full-stream-volume}
  \label{tab:full-stream-volume}
\end{table}

\section{Zero-suppressed Data}

There remains some options in choosing the exact zero-suppression (ZS) procedure.
For these data rate estimates a very simple procedure is assumed: Each
channel is processed to remove all digitized time bins which are below
the given ADC threshold and a single number is added to the start of a
run of above-threshold bins which gives its starting time bin.

The ZS threshold is taken as the ADC equivalent to a
\chargezsthreshold
deposition near the CPA and localized such that it passes near one
induction wire and is collected on one collection wire.
Given the requirement that the minimum signal to noise is
\chargeminsignalnoiseratio this ZS threshold represents at least $3\sigma$
noise exclusion.
For the purpose of this estimate it is assumed that all noise is
removed.
The threshold is low enough that most pertinent activity in the
detector volume still be observed in ZS data.


\begin{table}[htbp]
  \centering
  \caption{Parameters pertaining to zero-suppressed data.}
  \input{annex-rate/gen/zs-parameters-table}
  \label{tab:zs-parameters-table}
\end{table}

Because, by construction, the ZS is assumed to remove electronics
noise, ZS data rate depends simply on the size of a class of event and
the rate at which it is expected to occur.
This information is summarized in table~\ref{tab:zs-volume}.


\begin{table}[htbp]
  \centering
  \caption{Data rate estimations for ZS data from various sources.
  An additional FS data estimation is given for supernova burst (SNB).}
  \input{annex-rate/gen/zs-volume-table}
  \label{tab:zs-volume}
\end{table}

The beam rate is averaged over full year assuming run fraction of
\beamrunfraction, a rep rate of \beamreprate and a beam spill occupancy
of \beameventoccupancy.

The Supernova Burst data is estimated assuming a false-positive SNB
rate of \snbrate and a readout time of \snbreadouttime.
It should be noted that both these parameters are subject to
modification and are used to provide benchmark examples.
It is assumed that such candidates are made up of $^{39}Ar$ events.
Actual SNB events will have neutrino energies as high as
\SI{100}{\MeV}.
Roughly speaking, 1000 events across DUNE are expected from a real SNB
with the neutrino front lasting some \SI{10}{\second} giving nor more
than interaction per APA readout with the rest of the readout time
filled with radioactivity.
Each neutrino is expected to contribute about 10\% of the data of the
$\sim$\si{\GeV} beam events or about \SI{1}{\mega\byte}.
For the entire SNB this would then add about \SI{1}{\giga\byte} to the
event and thus does not greatly impact the estimate.

The SNB event size is what must be acquired promptly through that
readout time and the data rate is averaged over the year.
The annual data volume is what would be saved to disk if all false
positive events are kept.
The table also includes the an estimation assuming full-stream data is
kept for the SNB candidates.

\section{High-energy Threshold}

The final threshold that is considered is the one dubbed high-energy (HE).
For the sake of these estimates the HE threshold is chosen to be above
the background activity due to radioactive decay below \chargehethreshold.
A more careful study is needed to determine what this threshold will be.
The data rates with the HE threshold applied are summarized in table~\ref{tab:he-volume}.

\begin{table}[htbp]
  \centering
  \caption{Data rate estimations for data from activity above the
    high-energy (HE) threshold from various sources.}
  \input{annex-rate/gen/he-volume-table}
  \label{tab:he-volume}
\end{table}

Above the HE threshold, activity from the $^{39}$Ar events and any SNB
candidates will be invisible.
Actual SNB events, which have neutrino energies as high as
\SI{100}{\MeV}, they will be visible above this threshold but applying
such a high threshold to SNB candidates is not being considered and so
their data rate is not calculated with this assumption.




