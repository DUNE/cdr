\chapter{Characterization of Data Rates}
\label{ch:annex-rate}

\section{Overview}

The data rates estimations take as input a number of parameters from
designs, requirements and studies.
Derived parameters are generated based on these inputs and code
captured in the \textit{dune-params} package\footnote{\url{https://github.com/DUNE/dune-params}}.
As the inputs and estimations are refined the results presented in
this annex are regenerated.

Because the triggering and readout strategy of the DAQ and analyses
are not yet fully understand, the data rate estimation makes some
broad assumptions and leaves open some choices described in the
following subsections.



\section{Thresholds}

There are three threshold considered for the purpose of the data rate estimates.
The thresholds are assumed to be applied on per-wire and on the basis
of their ADC value.
The thresholds are assumed to affect the data rate coming out of the
DAQ and do not intend to imply other thresholds used internally to the
DAQ (for example in the anticipated ``trigger stream'').
The thresholds are:

\begin{description}
\item[full-stream] The full-stream (FS) threshold is no threshold at all.
FS data is data where every time bin on every channel is read out.
\item[zero-suppressed] The zero-suppressed (ZS) threshold is applied
  at $\approx 3\sigma$ above the mean electronics noise level.
  Given the requirement on signal/noise ratio and the wire spacing,
  this effectively places an energy threshold of
  \SI{0.3}{\MeV}.\fixme{There is also \SI{0.5}{\MeV} floating around
    and this should probably be added as a parameter.}
\item[high-energy] The high-energy (HE) threshold is one that is
  placed high enough to remove activity from radioactive decays but
  low enough to not impact activity from beam neutrino interactions or
  proton decay.
  Study is needed to determine this threshold but it is taken to be
  $\sim$\SI{5}{\MeV}.\fixme{Again, should this be a proper parameter?}
\end{description}

The design of the DAQ is expected to allow FS data acquisition.
It is also expected to be flexible enough to allow for different
thresholds to be applied based on indications from the data itself.

\section{Sources of Data}

Data is expected to be produced from a number of sources.
Each source will produce a different rate and depending on the
threshold applied.
Their data rates are estimated individually for each source and threshold.
This provides a means to evaluate different assumptions, designs and
strategies.

The sources of data that are considered are:

\begin{description}
\item[in-spill] Activity in the detector which
  is coincident in time and space with the passage of neutrinos from
  the beam through the detector.
\item[cosmic-$\mu$] Activity due to the
  passing of cosmic-ray muons through the detector.
\item[radioactivity] Activity due to the decay of $^{39}$Ar,
  U/Th and other radioactive isotopes.
\item[atm-$\nu$] Activity which is not in-spill and which is
  consistent with interactions from atmospheric neutrinos.
\end{description}

\section{Fundamental Parameters}

This section provides the fundamental parameters taken as input to the
data rate estimations.
The parameters are summarized in
table~\ref{tab:fundamental-parameters}

\begin{table}[htbp]
  \centering
  \caption{The fundamental parameters serving as input to data rate estimations.}
  \input{annex-rate/gen/fundamental-parameters-table}
  \label{tab:fundamental-parameters}
\end{table}

\fixme{These aren't all.}

\section{Full-stream Data}

Full-stream (FS) data is acquired with no ADC threshold.
It is obviously the most voluminous and also the most easy to estimate.
The parameters which apply to this data are given in table~\ref{tab:full-stream-parameters}.

\begin{table}[htbp]
  \centering
  \caption{Parameters pertaining to full-stream data rates.}
  \input{annex-rate/gen/full-stream-parameters-table}
  \label{tab:full-stream-parameters}
\end{table}

The expected data rates for different scenarios of FS data are given
in table~\ref{tab:full-stream-volume}

\begin{table}[htbp]
  \centering
  \caption{Data volumes and rates for full-stream data
    acquisition. FIXME: These numbers are currently wrong!}
  \input{annex-rate/gen/full-stream-volume}
  \label{tab:full-stream-volume}
\end{table}


\section{The tables}

The Liquid Argon TPC will produce a variety of signals due to various
physics processes taking place in the detector, such as scattering of
the beam neutrinos, cosmic ray muons, radiological backgrounds,
electronics noise and others.
For practical reasons, the signal processing systems will be
incorporate threshold values which will determine which part of data
is rejected and how the data stream needs to be treated at any given
time (cf. search for Supernova Burst events or nucleon decay).

Depending on the origin, these signals will be characterized by
specific spectra, energy scale and topologies.
In combination with the threshold settings and real-time algorithms
this will result in different rates of occurrence and volume of data
produced (either per nominal event or per unit time).

It is important to account for this information for the following reasons:
\begin{itemize}
\item An attempt must be made to understand, quantify and optimize
  systematic uncertainties for each class of measurements
\item There are considerable implications of real-time data processing
  strategies and techniques of all of ``downstream'' data processing
  (e.g. offline), and in particular to the required mass storage
  volume.
  This, in turn, will affect the DUNE computing model and costs
  associated with the DUNE computing effort.
\end{itemize}


We recognize that not all the information exists at this point that is
necessary for exhaustive characterization of the DUNE data.
We will mark as such where appropriate.


The following sources of signal are included and itemized here to
facilitate reference in the rest of the text:
\begin{itemize}
\item ``Full stream'' - effectively continuous stream of digitized
  voltages read out from the TPC, not subject to thresholds.
  This can be likened to a video stream (although at a different
  scale).
\item ``ZS stream'' - the full stream subject to zero-suppression with
  a particular choice of threshold.
  With threshold optimal for the oscillation physics with beam
  neutrinos, this results in an order of magnitude less data than in
  the full stream.
\item ``Beam'' - beam neutrino events
\item ``SNB'' - supernova burst
\item noise - signals due to various electronic-related noises
\item ``rad'' - radiological and cosmogenic backgrounds combined.
  By the latter we mean radioactive decays and other signals caused by
  reaction of cosmic rays in the detector and various materials
  surrounding it.
\item ``cosmic $\mu$ - cosmic muons passing through the detector
  experiencing normal energy loss
\end{itemize}

\subsection{Event rate and sizes}

Table~\ref{tab:fundamental} summarizes the fundamental parameters
which are used as input to the data rate estimates given in this
section.

\begin{table}[htbp]
  \centering
  \caption{Fundamental parameters of the TPC and detector that are used as input to the data rate estimates.}
%  \input{annex-rate/fundamental-table.tex}
  \label{tab:fundamental}
\end{table}

One ``readout'' is a sampling of the data stream for a period of time
equal to the configured number of drifts per readout as shown in
table~\ref{tab:fundamental-values}.
\fixme{Explain why 2.4 drifts in a readout.}
This multiplier, the drift time over the drift distance and the sample
rate determines the number of samples/readout.


\subsubsection{Full Stream}

The \textit{full stream} (FS) ``activity'' is simply the case where
all channels are read out at the digitizing sampling rate.
This can produce a prodigious amount of data.


\begin{table}[htbp]
  \centering
  \caption{Calculation of \textit{full stream} data volume for
    \SI{40}{\kton}.}
%  \input{annex-rate/full-stream-table.tex}
  \label{tab:full-stream}
\end{table}

\subsubsection{Zero-suppressed Stream}

A threshold at a low ADC can be applied to the full-stream.
This is in order to suppress noise but is given the term
\textit{zero-suppression} (ZS).
A ZS-stream contains \textit{full stream readouts} as described above
but with all samples below the threshold removed with some added
encoding (number) to indicate where each contiguous run of
above-threshold samples begins inside the readout.\fixme{Is this
  accurate enough of a description?}

The intention of ZS is to remove electronics noise from what is
ultimately read out in order to reduce data volume with no negative
impact on the physics capabilities.
The requirement~\cite{docdb3383} on the electronic noise and
indirectly on the LAr purity is that one minimum-ionizing particle
(MIP) should produce an amount of charge that will result in a
digitized signal on the wire which is at least $15\times$ greater than
the noise.\fixme{The noise level is RMS?}.
The ZS threshold is taken to be set a level equivalent to the 30\% of
the ADC signal produce on a wire due to a MIP traversing the distance
of one wire pitch.\fixme{Does this make sense?}

The data rate for the \texttt{ZS stream} therefore depends on whatever
particle interactions may have occurred during the readout time.
It is not meaningful to speak about ``the data rate of the \textit{ZS
  stream}'' unless one specifies some other criteria applied to select
the readouts.
The remaining categories then make the assumption that a ZS threshold
of \num{0.3} MIP equivalent ADC is applied.

\subsubsection{Beam Events}

The data rate of events associated in time with spills of the proton
beam on target depend on many things: the beam spill repetition rate,
number of protons on target, annual running time, neutrino flux
spectrum, horn/target configuration, and event selection criteria.
In particular, the last case can be broken into two classes.
The most important contains events with energies consistent with known
and expected interactions by the beam neutrinos.
These are take to be events with energy greater than \SI{100}{\MeV}
and are called simply \textit{high energy beam events}.

The readouts with less than this analysis threshold, still above ZS
threshold and coincident with the beam spill may contain activity from
various sources.
A leading source of data rate is radioactive decay and described in
section~\ref{sec:radrates}.
Cosmic muons will usually be above the analysis threshold but will be
calculated separately on the assumption that reconstruction techniques
can reject them.
They are described in section~\ref{sec:cosmicmurates}.
For this section, both of these sources are estimated to contribute to
the beam event data rate as they will fall accidental in coincidence
with the beam spills.
The parameters assumed and derived rate estimations are given in
table~\ref{tab:beam-nu-rates}.

A third class of activity may be found in coincidence with beam spills
which is due to as yet unknown physics.
Given that detectors of higher energy thresholds and coarser grained
readout have not observed these events they are expected to occur at
low energy, if at all.


\begin{table}[htbp]
  \caption{Assumed parameters and rate estimation for beam events.}
  \centering
  \begin{tabular}[h]{l r}
\hline
beam rep rate & \SI{1}{\Hz}\\
beam run time & \SI{2e7}{\second/\year}\\
average event size & \SI{10}{\mebi\byte}\\
high energy events & \SI{1e4}{/\year}\\
\hline
high energy beam data & \SI{100}{\gibi\byte/\year}\\
rad coincident beam data & (fixme)\\
cosmic-$\mu$ coincident beam data & (fixme)\\
full stream beam data & \SI{471}{\pebi\byte/\year}\\
\hline
  \end{tabular}
  \label{tab:}
\end{table}

\fixme{After calculating the rates due to radioactive decays
  independent of ``trigger'' criteria, fill in how much contributes to
  the beam readouts.}

\fixme{After calculating the rates due to cosmics, multiply by the
  duty factor of the beam window and fill in above.}

\subsubsection{Radioactivity}

\subsubsection{Cosmic Muons}

\subsubsection{Supernova Burst}


\section{Characteristic Energy Thresholds}


Table~\ref{tab:physrates} summarizes the understanding of important
energy thresholds needed to study a particular study topic (physics,
calibration, selection efficiency).
The minimum threshold is that at which any lower threshold has no
additional benefit to the analysis.
The maximum threshold is that at which any higher will negatively
impact the analysis.
The threshold is understood to be interpreted as the amount of
ionizing energy deposited in the active volume of the far detector
and may span APAs.

\begin{table}[htbf]
  \centering
  \begin{tabular}{|l||l|l|l|}
    \hline
    Topic & min thresh & max thresh & trigger \\
    \hline
    \hline
    beam & 50 MeV & 500 MeV & spill \\
    \hline
    pdk & $\sim$few MeV & 100 MeV (see K) & self+see K+nuc. dexcite \\
    \hline
    atm$\nu$ & $\sim$few MeV & 50 MeV &
    self+see Michele $e$ \\
    atm$\nu$ & $\sim$100 MeV & 500 MeV &
    self+no Michele $e$ \\
    \hline
    snb & $\sim$MeV & 5 MeV & self+ZS stream+dump \\
    \hline
    noise & full stream?&$\sim$MeV& min bias?\\
    \hline
    rad &$\sim 0$ & $\sim$MEV & self+minbias\\
    \hline
    calib & ??? & ??? & ??? \\
    \hline
  \end{tabular}
  \caption{Summary thresholds required for different study topics
    considering \textbf{signal only}.
  Below the minimum threshold no further impact on the physics is
  expected.
  Above the maximum threshold the physics is negatively impacted.
  The ``???'' indicate input is still needed.}
  \label{tab:physrates}
\end{table}

\section{Other estimates}

\fixme{rough list for now, these numbers need to be moved into their
  proper subsection}
\begin{itemize}
\item 5 minutes reco CPU / cosmic muon (scale by energy dep to get
  beam event reco CPU?)
  (tj)
\item Want 10-100$\times$ MC events as data for beam events.
  (tj)
  How frequent?
  How long to retain?
\item cosmic muons are about 1M events/year in 30kt (tj)
Can scale in-beam rates by energy deposition to this assuming constant
byte-per-MeV/cm deposited?
\item Square all numbers with those in the science book  
\end{itemize}

